// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.databricks.outputs.JobTaskDbtTask;
import com.pulumi.databricks.outputs.JobTaskDependsOn;
import com.pulumi.databricks.outputs.JobTaskEmailNotifications;
import com.pulumi.databricks.outputs.JobTaskLibrary;
import com.pulumi.databricks.outputs.JobTaskNewCluster;
import com.pulumi.databricks.outputs.JobTaskNotebookTask;
import com.pulumi.databricks.outputs.JobTaskPipelineTask;
import com.pulumi.databricks.outputs.JobTaskPythonWheelTask;
import com.pulumi.databricks.outputs.JobTaskSparkJarTask;
import com.pulumi.databricks.outputs.JobTaskSparkPythonTask;
import com.pulumi.databricks.outputs.JobTaskSparkSubmitTask;
import com.pulumi.databricks.outputs.JobTaskSqlTask;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class JobTask {
    private final @Nullable JobTaskDbtTask dbtTask;
    private final @Nullable List<JobTaskDependsOn> dependsOns;
    private final @Nullable String description;
    /**
     * @return (List) An optional set of email addresses notified when runs of this job begin and complete and when this job is deleted. The default behavior is to not send any emails. This field is a block and is documented below.
     * 
     */
    private final @Nullable JobTaskEmailNotifications emailNotifications;
    /**
     * @return If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use `new_cluster` for greater reliability.
     * 
     */
    private final @Nullable String existingClusterId;
    /**
     * @return Identifier that can be referenced in `task` block, so that cluster is shared between tasks
     * 
     */
    private final @Nullable String jobClusterKey;
    /**
     * @return (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks.Cluster resource.
     * 
     */
    private final @Nullable List<JobTaskLibrary> libraries;
    /**
     * @return (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED result_state or INTERNAL_ERROR life_cycle_state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry.
     * 
     */
    private final @Nullable Integer maxRetries;
    /**
     * @return (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
     * 
     */
    private final @Nullable Integer minRetryIntervalMillis;
    /**
     * @return Same set of parameters as for databricks.Cluster resource.
     * 
     */
    private final @Nullable JobTaskNewCluster newCluster;
    private final @Nullable JobTaskNotebookTask notebookTask;
    private final @Nullable JobTaskPipelineTask pipelineTask;
    private final @Nullable JobTaskPythonWheelTask pythonWheelTask;
    /**
     * @return (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
     * 
     */
    private final @Nullable Boolean retryOnTimeout;
    private final @Nullable JobTaskSparkJarTask sparkJarTask;
    private final @Nullable JobTaskSparkPythonTask sparkPythonTask;
    private final @Nullable JobTaskSparkSubmitTask sparkSubmitTask;
    private final @Nullable JobTaskSqlTask sqlTask;
    private final @Nullable String taskKey;
    /**
     * @return (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
     * 
     */
    private final @Nullable Integer timeoutSeconds;

    @CustomType.Constructor
    private JobTask(
        @CustomType.Parameter("dbtTask") @Nullable JobTaskDbtTask dbtTask,
        @CustomType.Parameter("dependsOns") @Nullable List<JobTaskDependsOn> dependsOns,
        @CustomType.Parameter("description") @Nullable String description,
        @CustomType.Parameter("emailNotifications") @Nullable JobTaskEmailNotifications emailNotifications,
        @CustomType.Parameter("existingClusterId") @Nullable String existingClusterId,
        @CustomType.Parameter("jobClusterKey") @Nullable String jobClusterKey,
        @CustomType.Parameter("libraries") @Nullable List<JobTaskLibrary> libraries,
        @CustomType.Parameter("maxRetries") @Nullable Integer maxRetries,
        @CustomType.Parameter("minRetryIntervalMillis") @Nullable Integer minRetryIntervalMillis,
        @CustomType.Parameter("newCluster") @Nullable JobTaskNewCluster newCluster,
        @CustomType.Parameter("notebookTask") @Nullable JobTaskNotebookTask notebookTask,
        @CustomType.Parameter("pipelineTask") @Nullable JobTaskPipelineTask pipelineTask,
        @CustomType.Parameter("pythonWheelTask") @Nullable JobTaskPythonWheelTask pythonWheelTask,
        @CustomType.Parameter("retryOnTimeout") @Nullable Boolean retryOnTimeout,
        @CustomType.Parameter("sparkJarTask") @Nullable JobTaskSparkJarTask sparkJarTask,
        @CustomType.Parameter("sparkPythonTask") @Nullable JobTaskSparkPythonTask sparkPythonTask,
        @CustomType.Parameter("sparkSubmitTask") @Nullable JobTaskSparkSubmitTask sparkSubmitTask,
        @CustomType.Parameter("sqlTask") @Nullable JobTaskSqlTask sqlTask,
        @CustomType.Parameter("taskKey") @Nullable String taskKey,
        @CustomType.Parameter("timeoutSeconds") @Nullable Integer timeoutSeconds) {
        this.dbtTask = dbtTask;
        this.dependsOns = dependsOns;
        this.description = description;
        this.emailNotifications = emailNotifications;
        this.existingClusterId = existingClusterId;
        this.jobClusterKey = jobClusterKey;
        this.libraries = libraries;
        this.maxRetries = maxRetries;
        this.minRetryIntervalMillis = minRetryIntervalMillis;
        this.newCluster = newCluster;
        this.notebookTask = notebookTask;
        this.pipelineTask = pipelineTask;
        this.pythonWheelTask = pythonWheelTask;
        this.retryOnTimeout = retryOnTimeout;
        this.sparkJarTask = sparkJarTask;
        this.sparkPythonTask = sparkPythonTask;
        this.sparkSubmitTask = sparkSubmitTask;
        this.sqlTask = sqlTask;
        this.taskKey = taskKey;
        this.timeoutSeconds = timeoutSeconds;
    }

    public Optional<JobTaskDbtTask> dbtTask() {
        return Optional.ofNullable(this.dbtTask);
    }
    public List<JobTaskDependsOn> dependsOns() {
        return this.dependsOns == null ? List.of() : this.dependsOns;
    }
    public Optional<String> description() {
        return Optional.ofNullable(this.description);
    }
    /**
     * @return (List) An optional set of email addresses notified when runs of this job begin and complete and when this job is deleted. The default behavior is to not send any emails. This field is a block and is documented below.
     * 
     */
    public Optional<JobTaskEmailNotifications> emailNotifications() {
        return Optional.ofNullable(this.emailNotifications);
    }
    /**
     * @return If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use `new_cluster` for greater reliability.
     * 
     */
    public Optional<String> existingClusterId() {
        return Optional.ofNullable(this.existingClusterId);
    }
    /**
     * @return Identifier that can be referenced in `task` block, so that cluster is shared between tasks
     * 
     */
    public Optional<String> jobClusterKey() {
        return Optional.ofNullable(this.jobClusterKey);
    }
    /**
     * @return (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks.Cluster resource.
     * 
     */
    public List<JobTaskLibrary> libraries() {
        return this.libraries == null ? List.of() : this.libraries;
    }
    /**
     * @return (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED result_state or INTERNAL_ERROR life_cycle_state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry.
     * 
     */
    public Optional<Integer> maxRetries() {
        return Optional.ofNullable(this.maxRetries);
    }
    /**
     * @return (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
     * 
     */
    public Optional<Integer> minRetryIntervalMillis() {
        return Optional.ofNullable(this.minRetryIntervalMillis);
    }
    /**
     * @return Same set of parameters as for databricks.Cluster resource.
     * 
     */
    public Optional<JobTaskNewCluster> newCluster() {
        return Optional.ofNullable(this.newCluster);
    }
    public Optional<JobTaskNotebookTask> notebookTask() {
        return Optional.ofNullable(this.notebookTask);
    }
    public Optional<JobTaskPipelineTask> pipelineTask() {
        return Optional.ofNullable(this.pipelineTask);
    }
    public Optional<JobTaskPythonWheelTask> pythonWheelTask() {
        return Optional.ofNullable(this.pythonWheelTask);
    }
    /**
     * @return (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
     * 
     */
    public Optional<Boolean> retryOnTimeout() {
        return Optional.ofNullable(this.retryOnTimeout);
    }
    public Optional<JobTaskSparkJarTask> sparkJarTask() {
        return Optional.ofNullable(this.sparkJarTask);
    }
    public Optional<JobTaskSparkPythonTask> sparkPythonTask() {
        return Optional.ofNullable(this.sparkPythonTask);
    }
    public Optional<JobTaskSparkSubmitTask> sparkSubmitTask() {
        return Optional.ofNullable(this.sparkSubmitTask);
    }
    public Optional<JobTaskSqlTask> sqlTask() {
        return Optional.ofNullable(this.sqlTask);
    }
    public Optional<String> taskKey() {
        return Optional.ofNullable(this.taskKey);
    }
    /**
     * @return (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
     * 
     */
    public Optional<Integer> timeoutSeconds() {
        return Optional.ofNullable(this.timeoutSeconds);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(JobTask defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private @Nullable JobTaskDbtTask dbtTask;
        private @Nullable List<JobTaskDependsOn> dependsOns;
        private @Nullable String description;
        private @Nullable JobTaskEmailNotifications emailNotifications;
        private @Nullable String existingClusterId;
        private @Nullable String jobClusterKey;
        private @Nullable List<JobTaskLibrary> libraries;
        private @Nullable Integer maxRetries;
        private @Nullable Integer minRetryIntervalMillis;
        private @Nullable JobTaskNewCluster newCluster;
        private @Nullable JobTaskNotebookTask notebookTask;
        private @Nullable JobTaskPipelineTask pipelineTask;
        private @Nullable JobTaskPythonWheelTask pythonWheelTask;
        private @Nullable Boolean retryOnTimeout;
        private @Nullable JobTaskSparkJarTask sparkJarTask;
        private @Nullable JobTaskSparkPythonTask sparkPythonTask;
        private @Nullable JobTaskSparkSubmitTask sparkSubmitTask;
        private @Nullable JobTaskSqlTask sqlTask;
        private @Nullable String taskKey;
        private @Nullable Integer timeoutSeconds;

        public Builder() {
    	      // Empty
        }

        public Builder(JobTask defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.dbtTask = defaults.dbtTask;
    	      this.dependsOns = defaults.dependsOns;
    	      this.description = defaults.description;
    	      this.emailNotifications = defaults.emailNotifications;
    	      this.existingClusterId = defaults.existingClusterId;
    	      this.jobClusterKey = defaults.jobClusterKey;
    	      this.libraries = defaults.libraries;
    	      this.maxRetries = defaults.maxRetries;
    	      this.minRetryIntervalMillis = defaults.minRetryIntervalMillis;
    	      this.newCluster = defaults.newCluster;
    	      this.notebookTask = defaults.notebookTask;
    	      this.pipelineTask = defaults.pipelineTask;
    	      this.pythonWheelTask = defaults.pythonWheelTask;
    	      this.retryOnTimeout = defaults.retryOnTimeout;
    	      this.sparkJarTask = defaults.sparkJarTask;
    	      this.sparkPythonTask = defaults.sparkPythonTask;
    	      this.sparkSubmitTask = defaults.sparkSubmitTask;
    	      this.sqlTask = defaults.sqlTask;
    	      this.taskKey = defaults.taskKey;
    	      this.timeoutSeconds = defaults.timeoutSeconds;
        }

        public Builder dbtTask(@Nullable JobTaskDbtTask dbtTask) {
            this.dbtTask = dbtTask;
            return this;
        }
        public Builder dependsOns(@Nullable List<JobTaskDependsOn> dependsOns) {
            this.dependsOns = dependsOns;
            return this;
        }
        public Builder dependsOns(JobTaskDependsOn... dependsOns) {
            return dependsOns(List.of(dependsOns));
        }
        public Builder description(@Nullable String description) {
            this.description = description;
            return this;
        }
        public Builder emailNotifications(@Nullable JobTaskEmailNotifications emailNotifications) {
            this.emailNotifications = emailNotifications;
            return this;
        }
        public Builder existingClusterId(@Nullable String existingClusterId) {
            this.existingClusterId = existingClusterId;
            return this;
        }
        public Builder jobClusterKey(@Nullable String jobClusterKey) {
            this.jobClusterKey = jobClusterKey;
            return this;
        }
        public Builder libraries(@Nullable List<JobTaskLibrary> libraries) {
            this.libraries = libraries;
            return this;
        }
        public Builder libraries(JobTaskLibrary... libraries) {
            return libraries(List.of(libraries));
        }
        public Builder maxRetries(@Nullable Integer maxRetries) {
            this.maxRetries = maxRetries;
            return this;
        }
        public Builder minRetryIntervalMillis(@Nullable Integer minRetryIntervalMillis) {
            this.minRetryIntervalMillis = minRetryIntervalMillis;
            return this;
        }
        public Builder newCluster(@Nullable JobTaskNewCluster newCluster) {
            this.newCluster = newCluster;
            return this;
        }
        public Builder notebookTask(@Nullable JobTaskNotebookTask notebookTask) {
            this.notebookTask = notebookTask;
            return this;
        }
        public Builder pipelineTask(@Nullable JobTaskPipelineTask pipelineTask) {
            this.pipelineTask = pipelineTask;
            return this;
        }
        public Builder pythonWheelTask(@Nullable JobTaskPythonWheelTask pythonWheelTask) {
            this.pythonWheelTask = pythonWheelTask;
            return this;
        }
        public Builder retryOnTimeout(@Nullable Boolean retryOnTimeout) {
            this.retryOnTimeout = retryOnTimeout;
            return this;
        }
        public Builder sparkJarTask(@Nullable JobTaskSparkJarTask sparkJarTask) {
            this.sparkJarTask = sparkJarTask;
            return this;
        }
        public Builder sparkPythonTask(@Nullable JobTaskSparkPythonTask sparkPythonTask) {
            this.sparkPythonTask = sparkPythonTask;
            return this;
        }
        public Builder sparkSubmitTask(@Nullable JobTaskSparkSubmitTask sparkSubmitTask) {
            this.sparkSubmitTask = sparkSubmitTask;
            return this;
        }
        public Builder sqlTask(@Nullable JobTaskSqlTask sqlTask) {
            this.sqlTask = sqlTask;
            return this;
        }
        public Builder taskKey(@Nullable String taskKey) {
            this.taskKey = taskKey;
            return this;
        }
        public Builder timeoutSeconds(@Nullable Integer timeoutSeconds) {
            this.timeoutSeconds = timeoutSeconds;
            return this;
        }        public JobTask build() {
            return new JobTask(dbtTask, dependsOns, description, emailNotifications, existingClusterId, jobClusterKey, libraries, maxRetries, minRetryIntervalMillis, newCluster, notebookTask, pipelineTask, pythonWheelTask, retryOnTimeout, sparkJarTask, sparkPythonTask, sparkSubmitTask, sqlTask, taskKey, timeoutSeconds);
        }
    }
}
